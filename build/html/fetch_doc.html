

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Answers Engine Fetch &mdash; AnswersEngine  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="High Level Concepts" href="high_level.html" />
    <link rel="prev" title="Answers Engine Fetch documentation" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> AnswersEngine
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Answers Engine Fetch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#install-answersengine-command-line-interface-using-rubygems">Install AnswersEngine Command Line Interface using rubygems</a></li>
<li class="toctree-l3"><a class="reference internal" href="#get-your-access-token">Get your access token</a></li>
<li class="toctree-l3"><a class="reference internal" href="#set-environment-variable-of-your-access-token">Set environment variable of your access token</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-the-scraper">Create the scraper</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deploying-the-scraper">Deploying the scraper</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-the-scraper">Run the scraper</a></li>
<li class="toctree-l3"><a class="reference internal" href="#viewing-the-job-stats">Viewing the Job Stats</a></li>
<li class="toctree-l3"><a class="reference internal" href="#viewing-the-job-pages">Viewing the Job Pages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#viewing-a-global-page-content">Viewing a Global Page Content</a></li>
<li class="toctree-l3"><a class="reference internal" href="#view-the-scraper-output">View the scraper output</a></li>
<li class="toctree-l3"><a class="reference internal" href="#view-the-scraper-logs">View the scraper logs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="high_level.html">High Level Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_access.html">User Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="scraper_dev_workflow.html">Scraper Development workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="scraper_maintenance_workflow.html">Scraper Maintenance workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="coding_tutorials.html">Coding Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="how_tos.html">How-Tos</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AnswersEngine</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Answers Engine Fetch</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/fetch_doc.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="answers-engine-fetch">
<h1>Answers Engine Fetch<a class="headerlink" href="#answers-engine-fetch" title="Permalink to this headline">¶</a></h1>
<p>Fetch is a platform where you can scrape data from the internet quickly and easily without incurring significant costs.
We do this by allowing you to scrape data from the shared-cache of contents that Fetch has collectively downloaded from the Internet for other users to scrape.
Your scraping from the cached-content does not necessarily prevent you from getting the freshest content. In fact, you can specify how fresh the contents you want to scrape are by specifying your freshness-type and also specifying that the content should be “force fetched” or not.</p>
<p>Keep in mind that any page that Fetch downloads for your scraper, will be stored on the shared-cache, and will be available to other Fetch users to use for their own scrapers. This reuse of cached pages allows every Fetch users to collectively save cost and save time as they scrape data from the Internet.
Fetch is like curl, where you have lower level control of HTTP request, such as request method, headers, body, and more.</p>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<p>In this getting started section, we will get you started with installing the necessary requirements, and then deploying and running an existing scraper into AnswerEngine Fetch. Currently we support ruby 2.4.4 and 2.5.3.</p>
<div class="section" id="install-answersengine-command-line-interface-using-rubygems">
<h3>Install AnswersEngine Command Line Interface using rubygems<a class="headerlink" href="#install-answersengine-command-line-interface-using-rubygems" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ gem install answersengine
Successfully installed answersengine-0.2.3
Parsing documentation <span class="k">for</span> answersengine-0.2.3
Done installing documentation <span class="k">for</span> answersengine after <span class="m">0</span> seconds
<span class="m">1</span> gem installed
</pre></div>
</div>
</div>
<div class="section" id="get-your-access-token">
<h3>Get your access token<a class="headerlink" href="#get-your-access-token" title="Permalink to this headline">¶</a></h3>
<p>You can create “account_admin” or “basic” token.
The difference between the two is an “account_admin” token can create other access tokens, whereas basic account could not.</p>
</div>
<div class="section" id="set-environment-variable-of-your-access-token">
<h3>Set environment variable of your access token<a class="headerlink" href="#set-environment-variable-of-your-access-token" title="Permalink to this headline">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ <span class="nb">export</span> <span class="nv">ANSWERSENGINE_TOKEN</span><span class="o">=</span>&lt;your_token_Here&gt;
</pre></div>
</div>
<p>Now you’re ready to go.</p>
</div>
<div class="section" id="create-the-scraper">
<h3>Create the scraper<a class="headerlink" href="#create-the-scraper" title="Permalink to this headline">¶</a></h3>
<p>In this step we will create a scraper on AnswersEngine, by specifying the scraper name, and the git repository where the scraper script comes from:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper create walmart-movies git@git.answersengine.com:scrapers/walmart-movies.git --workers <span class="m">1</span>
<span class="o">{</span>
 <span class="s2">&quot;name&quot;</span>: <span class="s2">&quot;walmart-movies&quot;</span>,
 <span class="s2">&quot;id&quot;</span>: <span class="m">54</span>,
 <span class="s2">&quot;account_id&quot;</span>: <span class="m">1</span>,
 <span class="s2">&quot;force_fetch&quot;</span>: false,
 <span class="s2">&quot;freshness_type&quot;</span>: <span class="s2">&quot;any&quot;</span>,
 <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:28:22.037768Z&quot;</span>,
 <span class="s2">&quot;git_repository&quot;</span>: <span class="s2">&quot;git@git.answersengine.com:scrapers/walmart-movies.git&quot;</span>,
 <span class="s2">&quot;git_branch&quot;</span>: <span class="s2">&quot;master&quot;</span>,
 <span class="s2">&quot;deployed_git_repository&quot;</span>: <span class="s2">&quot;git@git.answersengine.com:scrapers/walmart-movies.git&quot;</span>,
 <span class="s2">&quot;deployed_git_branch&quot;</span>: <span class="s2">&quot;master&quot;</span>,
 <span class="s2">&quot;deployed_commit_hash&quot;</span>: <span class="s2">&quot;e7d77d7622e7b71c32300eafd2d44a8429142fe3&quot;</span>,
 <span class="s2">&quot;deployed_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:28:22.037768Z&quot;</span>,
 <span class="s2">&quot;worker_count&quot;</span>: <span class="m">1</span>,
 <span class="s2">&quot;config&quot;</span>: <span class="o">{</span>
  <span class="s2">&quot;parsers&quot;</span>: <span class="o">[</span>
   <span class="o">{</span>
    <span class="s2">&quot;file&quot;</span>: <span class="s2">&quot;./parsers/part.rb&quot;</span>,
    <span class="s2">&quot;page_type&quot;</span>: <span class="s2">&quot;part&quot;</span>
   <span class="o">}</span>
  <span class="o">]</span>,
  <span class="s2">&quot;seeder&quot;</span>: <span class="o">{</span>
   <span class="s2">&quot;file&quot;</span>: <span class="s2">&quot;./seeder/seeder.rb&quot;</span>
  <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Let’s see if your scraper has been created.
Let’s look at the list of scrapers that you have now:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper list
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">&quot;name&quot;</span>: <span class="s2">&quot;ebay&quot;</span>,
  <span class="s2">&quot;id&quot;</span>: <span class="m">20</span>,
  <span class="s2">&quot;account_id&quot;</span>: <span class="m">1</span>,
  <span class="s2">&quot;force_fetch&quot;</span>: false,
  <span class="s2">&quot;freshness_type&quot;</span>: <span class="s2">&quot;any&quot;</span>,
  <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2018-11-26T22:00:43.007755Z&quot;</span>,
  <span class="s2">&quot;git_repository&quot;</span>: <span class="s2">&quot;https://github.com/answersengine/ebay-scraper.git&quot;</span>,
  <span class="s2">&quot;git_branch&quot;</span>: <span class="s2">&quot;master&quot;</span>,
  <span class="s2">&quot;deployed_git_repository&quot;</span>: <span class="s2">&quot;https://github.com/answersengine/ebay-scraper.git&quot;</span>,
  <span class="s2">&quot;deployed_git_branch&quot;</span>: <span class="s2">&quot;master&quot;</span>,
  <span class="s2">&quot;deployed_commit_hash&quot;</span>: <span class="s2">&quot;7bd6091d97a17cf8ee769e00ac285123c41aaf4f&quot;</span>,
  <span class="s2">&quot;deployed_at&quot;</span>: <span class="s2">&quot;2018-11-28T06:13:56.571052Z&quot;</span>,
  <span class="s2">&quot;worker_count&quot;</span>: <span class="m">1</span>,
...
</pre></div>
</div>
<p>Or if you’d like to see your specific scraper, you can do:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper show walmart-movies
<span class="o">{</span>
 <span class="s2">&quot;name&quot;</span>: <span class="s2">&quot;walmart-movies&quot;</span>,
 <span class="s2">&quot;id&quot;</span>: <span class="m">18</span>,
 <span class="s2">&quot;account_id&quot;</span>: <span class="m">1</span>,
 <span class="s2">&quot;force_fetch&quot;</span>: false,
 <span class="s2">&quot;freshness_type&quot;</span>: <span class="s2">&quot;any&quot;</span>,
 <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:28:22.037768Z&quot;</span>,
 <span class="s2">&quot;git_repository&quot;</span>: <span class="s2">&quot;git@git.answersengine.com:scrapers/walmart-movies.git&quot;</span>,
 <span class="s2">&quot;git_branch&quot;</span>: <span class="s2">&quot;master&quot;</span>,
 <span class="s2">&quot;deployed_git_repository&quot;</span>: <span class="s2">&quot;git@git.answersengine.com:scrapers/walmart-movies.git&quot;</span>,
...
</pre></div>
</div>
<p>Now that we have created the scraper, we need to deploy.</p>
</div>
<div class="section" id="deploying-the-scraper">
<h3>Deploying the scraper<a class="headerlink" href="#deploying-the-scraper" title="Permalink to this headline">¶</a></h3>
<p>Once we have created the scraper, let’s deploy it from the git repo that you have specified.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper deploy walmart-movies
Deploying scraper. This may take a <span class="k">while</span>...
<span class="o">{</span>
 <span class="s2">&quot;id&quot;</span>: <span class="m">135</span>,
 <span class="s2">&quot;scraper_id&quot;</span>: <span class="m">18</span>,
 <span class="s2">&quot;commit_hash&quot;</span>: <span class="s2">&quot;e7d77d7622e7b71c32300eafd2d44a8429142fe3&quot;</span>,
 <span class="s2">&quot;git_repository&quot;</span>: <span class="s2">&quot;git@git.answersengine.com:scrapers/walmart-movies.git&quot;</span>,
 <span class="s2">&quot;git_branch&quot;</span>: <span class="s2">&quot;master&quot;</span>,
 <span class="s2">&quot;errors&quot;</span>: null,
 <span class="s2">&quot;success&quot;</span>: true,
 <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:48:22.037768Z&quot;</span>,
 <span class="s2">&quot;config&quot;</span>: <span class="o">{</span>
  <span class="s2">&quot;parsers&quot;</span>: <span class="o">[</span>
   <span class="o">{</span>
    <span class="s2">&quot;file&quot;</span>: <span class="s2">&quot;./parsers/part.rb&quot;</span>,
    <span class="s2">&quot;page_type&quot;</span>: <span class="s2">&quot;part&quot;</span>
   <span class="o">}</span>
  <span class="o">]</span>,
  <span class="s2">&quot;seeder&quot;</span>: <span class="o">{</span>
   <span class="s2">&quot;file&quot;</span>: <span class="s2">&quot;./seeder/seeder.rb&quot;</span>
  <span class="o">}</span>
 <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Let’s see if the list of deployments, if you’re curious to know your deployment history.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper deployment list walmart-movies
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">&quot;id&quot;</span>: <span class="m">135</span>,
  <span class="s2">&quot;scraper_id&quot;</span>: <span class="m">18</span>,
  <span class="s2">&quot;commit_hash&quot;</span>: <span class="s2">&quot;e7d77d7622e7b71c32300eafd2d44a8429142fe3&quot;</span>,
  <span class="s2">&quot;git_repository&quot;</span>: <span class="s2">&quot;git@git.answersengine.com:scrapers/walmart-movies.git&quot;</span>,
  <span class="s2">&quot;git_branch&quot;</span>: <span class="s2">&quot;master&quot;</span>,
...
</pre></div>
</div>
</div>
<div class="section" id="run-the-scraper">
<h3>Run the scraper<a class="headerlink" href="#run-the-scraper" title="Permalink to this headline">¶</a></h3>
<p>Now that the scraper codes has been deployed, let’s run it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper start walmart-movies
Starting a scrape job...
<span class="o">{</span>
 <span class="s2">&quot;id&quot;</span>: <span class="m">135</span>,
 <span class="s2">&quot;scraper_id&quot;</span>: <span class="m">18</span>,
 <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:52:22.037768Z&quot;</span>,
 <span class="s2">&quot;freshness&quot;</span>: null,
 <span class="s2">&quot;force_fetch&quot;</span>: false,
 <span class="s2">&quot;status&quot;</span>: <span class="s2">&quot;active&quot;</span>,
 <span class="s2">&quot;seeding_at&quot;</span>: null,
 <span class="s2">&quot;seeding_failed_at&quot;</span>: null,
 <span class="s2">&quot;seeded_at&quot;</span>: null,
 <span class="s2">&quot;seeding_try_count&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;seeding_fail_count&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;seeding_error_count&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;worker_count&quot;</span>: <span class="m">1</span>
<span class="o">}</span>
</pre></div>
</div>
<p>This will now then create a scraping job, which will start fetching pages for you, and parsing them into the outputs.</p>
<p>You can also see all jobs that was created on the scraper.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper job list walmart-movies
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">&quot;id&quot;</span>: <span class="m">135</span>,
  <span class="s2">&quot;scraper_name&quot;</span>: <span class="s2">&quot;walmart-movies&quot;</span>,
  <span class="s2">&quot;scraper_id&quot;</span>: <span class="m">18</span>,
  <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:48:22.037768Z&quot;</span>,
...
</pre></div>
</div>
<p>To view the current job on the scraper.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper job show walmart-movies
<span class="o">{</span>
 <span class="s2">&quot;id&quot;</span>: <span class="m">135</span>,
 <span class="s2">&quot;scraper_name&quot;</span>: <span class="s2">&quot;walmart-movies&quot;</span>,
 <span class="s2">&quot;scraper_id&quot;</span>: <span class="m">18</span>,
 <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:48:22.037768Z&quot;</span>,
...
</pre></div>
</div>
</div>
<div class="section" id="viewing-the-job-stats">
<h3>Viewing the Job Stats<a class="headerlink" href="#viewing-the-job-stats" title="Permalink to this headline">¶</a></h3>
<p>While the job is running, let’s look how the job is doing by looking at the stats. You’ll first need to get the ID form the job list command above.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper stats walmart-movies
<span class="o">{</span>
 <span class="s2">&quot;job_id&quot;</span>: <span class="m">135</span>,
 <span class="s2">&quot;pages&quot;</span>: <span class="m">822</span>,
 <span class="s2">&quot;fetched_pages&quot;</span>: <span class="m">822</span>,
 <span class="s2">&quot;to_fetch&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;fetching_failed&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;fetched_from_web&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;fetched_from_cache&quot;</span>: <span class="m">822</span>,
 <span class="s2">&quot;parsed_pages&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;to_parse&quot;</span>: <span class="m">822</span>,
 <span class="s2">&quot;parsing_failed&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;outputs&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;output_collections&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;workers&quot;</span>: <span class="m">1</span>,
 <span class="s2">&quot;time_stamp&quot;</span>: <span class="s2">&quot;2019-03-12T10:48:22.037768Z&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="viewing-the-job-pages">
<h3>Viewing the Job Pages<a class="headerlink" href="#viewing-the-job-pages" title="Permalink to this headline">¶</a></h3>
<p>Let’s see the pages that has been added by the seeder script into this job.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper page list walmart-movies
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">&quot;gid&quot;</span>: <span class="s2">&quot;www.walmart.com-4aa9b6bd1f2717409c22d58c4870471e&quot;</span>, <span class="c1"># Global ID</span>
  <span class="s2">&quot;job_id&quot;</span>: <span class="m">135</span>,
  <span class="s2">&quot;page_type&quot;</span>: <span class="s2">&quot;listings&quot;</span>,
  <span class="s2">&quot;method&quot;</span>: <span class="s2">&quot;GET&quot;</span>,
  <span class="s2">&quot;url&quot;</span>: <span class="s2">&quot;https://www.walmart.com/browse/movies-tv-shows/4096?facet=new_releases:Last+90+Days&quot;</span>,
  <span class="s2">&quot;effective_url&quot;</span>: <span class="s2">&quot;https://www.walmart.com/browse/movies-tv-shows/4096?facet=new_releases:Last+90+Days&quot;</span>,
  <span class="s2">&quot;headers&quot;</span>: <span class="s2">&quot;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&quot;</span>,
...
</pre></div>
</div>
</div>
<div class="section" id="viewing-a-global-page-content">
<h3>Viewing a Global Page Content<a class="headerlink" href="#viewing-a-global-page-content" title="Permalink to this headline">¶</a></h3>
<p>You may be wondering what is a Global Page.
A Global Page acts like a shared-cache that AnswersEngine fetches for all their users as they perform scraping. This shared-cache allows every users to collectively benefit from lower cost and higher performance of extracting data from the Internet.</p>
<p>Now that you’ve seen the pages that has been added into this job, let’s see the content of the page by copying and pasting a page’s GID(Global ID) into the following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine globalpage content www.walmart.com-4aa9b6bd1f2717409c22d58c4870471e
Preview content url: <span class="s2">&quot;https://fetch.answersengine.com/public/global_pages/preview/HS2RNNi0uKe2YQ3tlU-cedGCWhRHgLcm5PWTwTVx0VLs5yjlOt6bE8qma7lzv6oCfUSYBNHu3IpXK70961lRhcqruPg5xa29OmuSJvolz_ONcVV2nmeMfJx8tSe_jRi8JW1qIfD7O8Rchf3XdO10pfjgICiV_FBczWPGYmg3rNLGcHMk5UGseJcl7maAGvN5bhvrwesscrODp_mni894gKz8a9v3GTFtjVGUgexS-dEu2DKTfe6SNb1ZKHj08SUCTM61P_Umg6XzF-bJBePMZuoX2b8nkXQ3mDw1-bdMJ-WPFUfQ01T5gtkoCBDuSFBg-T8YGETNEPNm0usglfWzsq4=&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="view-the-scraper-output">
<h3>View the scraper output<a class="headerlink" href="#view-the-scraper-output" title="Permalink to this headline">¶</a></h3>
<p>Job Outputs are stored in collections. If none is specified, it will be stored in the “default” collection.
Let’s view the outputs of a scraper job by first seeing what collections the scraper outputs to:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper output collection walmart-movies
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">&quot;collection&quot;</span>: <span class="s2">&quot;products&quot;</span>,
  <span class="s2">&quot;count&quot;</span>: <span class="m">72</span>
 <span class="o">}</span>
<span class="o">]</span>
</pre></div>
</div>
<p>In the result of the command line above, you will see the collection called “products.” Let’s look at the outputs inside the “products” collection:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper output list walmart-movies --collection products
<span class="o">[</span>
 <span class="o">{</span>
  <span class="s2">&quot;_collection&quot;</span>: <span class="s2">&quot;products&quot;</span>,
  <span class="s2">&quot;_created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:50:44.037768Z&quot;</span>,
  <span class="s2">&quot;_gid&quot;</span>: <span class="s2">&quot;www.walmart.com-a2232af59a8d52c356136f6674f532c5&quot;</span>,
  <span class="s2">&quot;_id&quot;</span>: <span class="s2">&quot;3de2e6b6e16749879f7e9bdd1ea3f0fc&quot;</span>,
  <span class="s2">&quot;_job_id&quot;</span>: <span class="m">1341</span>,
  <span class="s2">&quot;categories&quot;</span>: <span class="o">[</span>
   <span class="s2">&quot;Movies &amp; TV Shows&quot;</span>,
   <span class="s2">&quot;Movies&quot;</span>,
   <span class="s2">&quot;Documentaries&quot;</span>,
   <span class="s2">&quot;All Documentaries&quot;</span>
  <span class="o">]</span>,
  <span class="s2">&quot;current_price&quot;</span>: <span class="m">21</span>.89,
  <span class="s2">&quot;img_url&quot;</span>: <span class="s2">&quot;https://i5.walmartimages.com/asr/5064efdd-9c84-4f17-a107-2669a34b54ff_1.474fdc2d2d1ea64e45def9c0c5afb4c0.jpeg&quot;</span>,
  <span class="s2">&quot;original_price&quot;</span>: null,
  <span class="s2">&quot;publisher&quot;</span>: <span class="s2">&quot;Kino Lorber&quot;</span>,
  <span class="s2">&quot;rating&quot;</span>: null,
  <span class="s2">&quot;reviews_count&quot;</span>: <span class="m">0</span>,
  <span class="s2">&quot;title&quot;</span>: <span class="s2">&quot;International Sweethearts of Rhythm (DVD)&quot;</span>,
  <span class="s2">&quot;walmart_number&quot;</span>: <span class="s2">&quot;572439718&quot;</span>
 <span class="o">}</span>,
...
</pre></div>
</div>
</div>
<div class="section" id="view-the-scraper-logs">
<h3>View the scraper logs<a class="headerlink" href="#view-the-scraper-logs" title="Permalink to this headline">¶</a></h3>
<p>If there is an error that occured it will be shown in the job log.
Let’s see what’s in the log.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper log walmart-movies
</pre></div>
</div>
<p>You can view the log of what happens.</p>
<p>Congratulations! You’ve created and ran your first scraper.</p>
<p>Let’s now cleanup from this Getting Started section by canceling that running job.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ answersengine scraper job cancel walmart-movies
<span class="o">{</span>
 <span class="s2">&quot;id&quot;</span>: <span class="m">135</span>,
 <span class="s2">&quot;scraper_name&quot;</span>: <span class="s2">&quot;walmart-movies&quot;</span>,
 <span class="s2">&quot;scraper_id&quot;</span>: <span class="m">18</span>,
 <span class="s2">&quot;created_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:48:22.058468Z&quot;</span>,
 <span class="s2">&quot;freshness&quot;</span>: null,
 <span class="s2">&quot;force_fetch&quot;</span>: false,
 <span class="s2">&quot;status&quot;</span>: <span class="s2">&quot;cancelled&quot;</span>,
 <span class="s2">&quot;seeding_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:49:42.035968Z&quot;</span>,
 <span class="s2">&quot;seeding_failed_at&quot;</span>: null,
 <span class="s2">&quot;seeded_at&quot;</span>: <span class="s2">&quot;2019-03-12T10:50:23.057768Z&quot;</span>,
 <span class="s2">&quot;seeding_try_count&quot;</span>: <span class="m">1</span>,
 <span class="s2">&quot;seeding_fail_count&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;seeding_error_count&quot;</span>: <span class="m">0</span>,
 <span class="s2">&quot;worker_count&quot;</span>: <span class="m">1</span>
<span class="o">}</span>
</pre></div>
</div>
<p>You’re now done with the Getting Started section. Next steps are to read the high level concepts, and do the tutorials.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="high_level.html" class="btn btn-neutral float-right" title="High Level Concepts" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Answers Engine Fetch documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, answersengine.com

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>